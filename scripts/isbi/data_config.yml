# Specify how the data needs to be sliced before feeding to the network.
# We use a 3D sliding window over the dataset to extract patches, which
# are then fed to the network as batches.
slicing_config:
  # Sliding window size (see padding)
  window_size: [1, 576, 576]
  # Sliding window stride
  stride: [1, 1, 1]
  # Sliding window downsampling ratio. The actual image size along a
  # dimension is the window_size divided by the downsampling ratio.
  # Example:
  #   window_size = [1, 512, 512], downsampling_ratio = [1, 2, 2] ==>
  #   slice shape = [1, 256, 256]
  downsampling_ratio: [1, 1, 1]
  # Reflect padding on the loaded volume. Follows numpy.pad semantics.
  padding: [[0, 0], [32, 32], [32, 32]]

    
# Specify paths to volumes
volume_config:
  # Raw data
  raw:
    path: '/home/papec/Work/neurodata_hdd/ntwrk_papec/ISBI2012/raw_train.tif'
    dtype: float32

  # Membranes
  membranes:
    path: '/home/papec/Work/neurodata_hdd/ntwrk_papec/ISBI2012/groundtruth.tif'
    dtype: float32
    nedt_gain: 0.5

# Specify configuration for the loader
loader_config:
  # Number of processes to use for loading data. Set to (say) 10 if you wish to
  # use 10 CPU cores, or to 0 if you wish to use the same process for training and
  # data-loading (generally not recommended).
  num_workers: 1
  batch_size: 5
  num_workers: 4
  drop_last: False
  pin_memory: True

